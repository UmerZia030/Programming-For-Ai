{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c0c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import re\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008d724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['Chapter_Number', \n",
    "            'Chapter_English', \n",
    "            'Chapter_Arabic', \n",
    "            'Section_Number', \n",
    "            'Section_English', \n",
    "            'Section_Arabic', \n",
    "            'Hadith_number', \n",
    "            'English_Hadith', \n",
    "            'English_Isnad', \n",
    "            'English_Matn', \n",
    "            'Arabic_Hadith', \n",
    "            'Arabic_Isnad', \n",
    "            'Arabic_Matn', \n",
    "            'Arabic_Comment', \n",
    "            'English_Grade', \n",
    "            'Arabic_Grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05832c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:\\LK-Hadith-Corpus-master\\LK-Hadith-Corpus-master\"  \n",
    "book_filenames = sorted(glob.glob(path + '//**//*.csv', recursive=True))  # reading all CSV files in all books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337c9f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "sample_file = pd.read_csv(book_filenames[0], names=colnames, skiprows=1)\n",
    "\n",
    "# Convert the DataFrame to a list of lists\n",
    "data = [sample_file.columns.tolist()] + sample_file.values.tolist()\n",
    "\n",
    "# Format and display the data using string formatting\n",
    "print(\"Sample Data:\")\n",
    "for row in data:\n",
    "    print(\"{:<15} {:<15} {:<15}\".format(*row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f0132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file = pd.read_csv(book_filenames[0], names=colnames, skiprows=1)\n",
    "print(\"Sample Data:\")\n",
    "print(sample_file.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ad6ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing Values:\")\n",
    "print(sample_file.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cc1d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # removing special characters, digits, etc.\n",
    "    if isinstance(text, str):\n",
    "        text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "        text = text.lower()\n",
    "    else:\n",
    "        text = ''\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b876c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hadiths = []\n",
    "\n",
    "for book_filename in book_filenames:\n",
    "    data = pd.read_csv(book_filename, names=colnames, skiprows=1)\n",
    "    \n",
    "    data['cleaned_english_hadith'] = data['English_Hadith'].apply(lambda x: str(x) if pd.notnull(x) else \"\")\n",
    "    \n",
    "    all_hadiths.extend(data['cleaned_english_hadith'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badc44de",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadith_df = pd.DataFrame({\n",
    "    'Hadith': all_hadiths\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53972e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# path = \"E:\\LK-Hadith-Corpus-master\\LK-Hadith-Corpus-master\"  \n",
    "\n",
    "# # Get all CSV files from all folders\n",
    "# book_filenames = sorted(glob.glob(path + '//**//*.csv', recursive=True))\n",
    "\n",
    "# # Iterate over each CSV file\n",
    "# for file in book_filenames:\n",
    "#     # Extract the book name from the folder name (assuming the folder name is the book name)\n",
    "#     book_name = os.path.basename(os.path.dirname(file))\n",
    "# #     print(book_name)\n",
    "#     # Read the CSV file into a DataFrame\n",
    "#     df = pd.read_csv(file)\n",
    "    \n",
    "#     # Insert the book name as the first column\n",
    "#     df.insert(0, 'Book_Name', book_name)\n",
    "    \n",
    "#     # Save the modified DataFrame back to the original file (or to a new file if you prefer)\n",
    "#     df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa421f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['Book_Name',\n",
    "            'Chapter_Number', \n",
    "            'Chapter_English', \n",
    "            'Chapter_Arabic', \n",
    "            'Section_Number', \n",
    "            'Section_English', \n",
    "            'Section_Arabic', \n",
    "            'Hadith_number', \n",
    "            'English_Hadith', \n",
    "            'English_Isnad', \n",
    "            'English_Matn', \n",
    "            'Arabic_Hadith', \n",
    "            'Arabic_Isnad', \n",
    "            'Arabic_Matn', \n",
    "            'Arabic_Comment', \n",
    "            'English_Grade', \n",
    "            'Arabic_Grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d803978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENGLISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b415ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hadiths = []\n",
    "\n",
    "for book_filename in book_filenames:\n",
    "    book_name = os.path.basename(os.path.dirname(book_filename))  # Extract book name from the directory\n",
    "\n",
    "    data = pd.read_csv(book_filename, names=colnames, skiprows=1)\n",
    "    \n",
    "    # Replace the 'Book_Name' column with the extracted book name\n",
    "    data['Book_Name'] = book_name \n",
    "\n",
    "    print(f\"Processing: {book_filename} | Extracted Book Name: {book_name}\")\n",
    "    \n",
    "    data['cleaned_english_hadith'] = data['English_Hadith'].apply(lambda x: str(x) if pd.notnull(x) else \"\")\n",
    "    \n",
    "    data = data[data['cleaned_english_hadith'] != \"\"]\n",
    "    \n",
    "    all_hadiths.extend(data[['Book_Name',\n",
    "                             'Chapter_Number', \n",
    "                             'Section_Number', \n",
    "                             'Hadith_number', \n",
    "                             'cleaned_english_hadith', \n",
    "                             'English_Grade']].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b952f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadith_df = pd.DataFrame(all_hadiths, columns=['Book_Name',\n",
    "                                               'Chapter_Number', \n",
    "                                               'Section_Number', \n",
    "                                               'Hadith_number', \n",
    "                                               'Hadith', \n",
    "                                               'English_Grade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6413fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadith_df = hadith_df[hadith_df['Hadith'] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da2711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadith_df.to_csv('cleaned_hadith_data_english.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1d7600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARABIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb94e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hadiths = []\n",
    "\n",
    "for book_filename in book_filenames:\n",
    "    data = pd.read_csv(book_filename, names=colnames, skiprows=1)\n",
    "    \n",
    "    data['cleaned_arabic_hadith'] = data['Arabic_Hadith'].apply(lambda x: str(x) if pd.notnull(x) else \"\")\n",
    "    \n",
    "    data = data[data['cleaned_arabic_hadith'] != \"\"]\n",
    "    \n",
    "    all_hadiths.extend(data[['Book_Name',\n",
    "                             'Chapter_Number', \n",
    "                             'Section_Number', \n",
    "                             'Hadith_number', \n",
    "                             'cleaned_arabic_hadith', \n",
    "                             'Arabic_Grade']].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c633904",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadith_df = pd.DataFrame(all_hadiths, columns=['Book_Name',\n",
    "                                               'Chapter_Number', \n",
    "                                               'Section_Number', \n",
    "                                               'Hadith_number', \n",
    "                                               'Hadith', \n",
    "                                               'Arabic_Grade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4e974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadith_df = hadith_df[hadith_df['Hadith'] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba506bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadith_df.to_csv('cleaned_hadith_data_arabic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e903ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadith_df = hadith_df[hadith_df['Hadith'] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa94d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<h4>Saving Cleaned Dataset</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a140e4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadith_df.to_csv('cleaned_hadith_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90ff1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
